{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EMNIST model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPeVAU6W/f2Ol6HbbcFuSbi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Enamulla577/EVAI/blob/main/Assignment-4/EMNIST_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3K9MctcU4OG"
      },
      "source": [
        "import torch\r\n",
        "import torchvision # provide access to datasets, models, transforms, utils, etc\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5q5cEXKU7lv"
      },
      "source": [
        "#Loading EMNIST dataset\r\n",
        "train_set = torchvision.datasets.EMNIST(\r\n",
        "    root='./data',\r\n",
        "    train = True,\r\n",
        "    split = 'bymerge',\r\n",
        "    download=True,\r\n",
        "    transform=transforms.Compose([\r\n",
        "        transforms.ToTensor()\r\n",
        "    ])\r\n",
        ")\r\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2Ly5nGTU-iu"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_set\r\n",
        "    ,batch_size=100\r\n",
        "    ,shuffle=True\r\n",
        ")"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5et216MAzUCU"
      },
      "source": [
        "# Define the Model\r\n",
        "\r\n",
        "class Network(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=3, padding=1) # input 28x28x1 | (3x3x1)x10  output-28x28x10 RF=3\r\n",
        "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, padding=1) # input 28x28x1 | (3x3x10)x10  28X28X10 RF=5\r\n",
        "        self.conv3 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, padding=1) #after max pooling 14x14x10 |(3x3x10)x20  14x14x20 RF=12\r\n",
        "        self.conv4 = nn.Conv2d(in_channels=20, out_channels=20, kernel_size=3, padding=1) #input 14x14x20|(3x3x20)x20   14x14x20 RF=14\r\n",
        "        self.conv5 = nn.Conv2d(in_channels=20, out_channels=30, kernel_size=3) #after max pooling 7x7x20 | 3x3x20x30  5x5x30 RF=30\r\n",
        "        self.conv6 = nn.Conv2d(in_channels=30, out_channels=10, kernel_size=3) #5x5x30 | (3x3x30)10 3x3x10 RF=32\r\n",
        "        self.out = nn.AvgPool2d(3, stride=2)  #1x1x10 RF=34\r\n",
        "        \r\n",
        "\r\n",
        "    def forward(self, t):\r\n",
        "        #  input layer\r\n",
        "        t = t\r\n",
        "\r\n",
        "        # (1) hidden conv layer\r\n",
        "        t = self.conv1(t)\r\n",
        "        t = F.relu(t)\r\n",
        "        \r\n",
        "        # (2) hidden conv layer\r\n",
        "        t = self.conv2(t)\r\n",
        "        t = F.relu(t)\r\n",
        "        t = F.max_pool2d(t, kernel_size=2, stride=2)\r\n",
        "       \r\n",
        "        # (3) hidden conv layer\r\n",
        "        t = self.conv3(t)\r\n",
        "        t = F.relu(t)\r\n",
        "        \r\n",
        "        # (4) hidden conv layer\r\n",
        "        t = self.conv4(t)\r\n",
        "        t = F.relu(t)\r\n",
        "        t = F.max_pool2d(t, kernel_size=2, stride=2)\r\n",
        "        \r\n",
        "        # (5) hidden conv layer\r\n",
        "        t = self.conv5(t)\r\n",
        "        t = F.relu(t)\r\n",
        "\r\n",
        "        # (6) hidden conv layer\r\n",
        "        t = self.conv6(t)\r\n",
        "        t = F.relu(t)\r\n",
        "        # output layer\r\n",
        "        t = self.out(t)\r\n",
        "        # t = t.softmax(t, dim=1)\r\n",
        "      \r\n",
        "        return t"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PynKG8Kq2Vhr",
        "outputId": "5de1e4e7-2ceb-406b-e01e-428c1738166e"
      },
      "source": [
        "network = Network()\r\n",
        "print(network)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv4): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(20, 30, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv6): Conv2d(30, 10, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (out): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKAZOmW45y9h",
        "outputId": "35fc1ae5-2eb3-4d89-9661-0a10f045e77c"
      },
      "source": [
        "sample = next(iter(train_set)) \n",
        "image, label = sample\n",
        "pred = network(image.unsqueeze(0))\n",
        "pred"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00]],\n",
              "\n",
              "         [[7.4309e-02]],\n",
              "\n",
              "         [[0.0000e+00]],\n",
              "\n",
              "         [[7.8198e-05]],\n",
              "\n",
              "         [[4.7964e-03]],\n",
              "\n",
              "         [[0.0000e+00]],\n",
              "\n",
              "         [[4.0292e-02]],\n",
              "\n",
              "         [[2.5999e-02]],\n",
              "\n",
              "         [[1.2490e-02]]]], grad_fn=<AvgPool2DBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9BujmRB6W-V",
        "outputId": "917f8e39-3848-4c08-b420-ff4046425645"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "model = Network()  # copying the net to the device\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 10, 28, 28]             100\n",
            "            Conv2d-2           [-1, 10, 28, 28]             910\n",
            "            Conv2d-3           [-1, 20, 14, 14]           1,820\n",
            "            Conv2d-4           [-1, 20, 14, 14]           3,620\n",
            "            Conv2d-5             [-1, 30, 5, 5]           5,430\n",
            "            Conv2d-6             [-1, 10, 3, 3]           2,710\n",
            "         AvgPool2d-7             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 14,590\n",
            "Trainable params: 14,590\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.19\n",
            "Params size (MB): 0.06\n",
            "Estimated Total Size (MB): 0.24\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOaD__lA_CWm"
      },
      "source": [
        "network = Network()\n",
        "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set\n",
        "    ,batch_size=100\n",
        "    ,shuffle=True\n",
        ")"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "I7boRtm2_INw",
        "outputId": "25e1d9b6-39ff-4a3e-b46c-4315f8048344"
      },
      "source": [
        "for epoch in range(20):\n",
        "\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "\n",
        "    for batch in train_loader: # Get Batch\n",
        "        images, labels = batch \n",
        "\n",
        "        preds = network(images) # Pass Batch\n",
        "        loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward() # Calculate Gradients\n",
        "        optimizer.step() # Update Weights\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_correct += get_num_correct(preds, labels)\n",
        "\n",
        "    print(\n",
        "        \"epoch\", epoch, \n",
        "        \"total_correct:\", total_correct, \n",
        "        \"loss:\", total_loss\n",
        "    )"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-701399c75fcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pass Batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Calculate Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2468\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2264\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2266\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2267\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2268\u001b[0m         \u001b[0;31m# dim == 3 or dim > 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: only batches of spatial targets supported (3D tensors) but got targets of dimension: 1"
          ]
        }
      ]
    }
  ]
}